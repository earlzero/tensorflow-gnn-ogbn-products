{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3098a1e9-3ca3-4d48-b42f-b8ab2f7702e1",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "\n",
    "Figure out how to display label for examples for validation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c205d800-aa97-4ec8-adbc-1a0b1aeffe50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/fastdata/ez/ml/ogb/.env/lib/python3.12/site-packages/outdated/__init__.py:36: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n",
      "2025-12-01 22:31:57.354913: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "import os\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "from ogb.nodeproppred import NodePropPredDataset\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_gnn as tfgnn\n",
    "from tensorflow_gnn import runner\n",
    "from typing import Mapping\n",
    "from tensorflow_gnn.experimental import sampler\n",
    "from tensorflow_gnn.models import mt_albis\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import functools\n",
    "import itertools\n",
    "from subgraph_dataset_provider import SubgraphDatasetProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ed9e675-558f-44c7-be94-9ef6bcc16294",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NodePropPredDataset(name = \"ogbn-products\", root = 'dataset/')\n",
    "split_idx = dataset.get_idx_split()\n",
    "train_idx, valid_idx, test_idx = split_idx[\"train\"], split_idx[\"valid\"], split_idx[\"test\"]\n",
    "NUM_TRAINING_SAMPLES=train_idx.shape[0]\n",
    "NUM_VALIDATION_SAMPLES = valid_idx.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff08c192-777b-4dda-8e70-6d016e575056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph, label = dataset[0]\n",
    "# mask0=np.isin(graph[\"edge_index\"][0],train_idx)\n",
    "# mask1=np.isin(graph[\"edge_index\"][1],train_idx)\n",
    "\n",
    "# mask = mask0 & mask1\n",
    "# indices = np.where(mask)[0]\n",
    "# train_edge_index=graph[\"edge_index\"][:, indices]\n",
    "# train_node_feat = graph[\"node_feat\"][train_idx,:]\n",
    "# train_label = label[train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c4a9d78-523c-4870-ab61-5db17576bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Trying validation set here\n",
    "# graph, label = dataset[0]\n",
    "# mask0=np.isin(graph[\"edge_index\"][0],valid_idx)\n",
    "# mask1=np.isin(graph[\"edge_index\"][1],valid_idx)\n",
    "\n",
    "# mask = mask0 & mask1\n",
    "# indices = np.where(mask)[0]\n",
    "# valid_edge_index=graph[\"edge_index\"][:, indices]\n",
    "# valid_node_feat = graph[\"node_feat\"][valid_idx,:]\n",
    "# valid_label = label[valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68bc4e94-0020-4eaf-9e7c-b450d02f9413",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_schema = tfgnn.read_schema(\"graph_schema.pbtxt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b192796-4c46-42d6-802b-637f7512aec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow_gnn.proto.graph_schema_pb2.GraphSchema"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# graph_schema = tfgnn.read_schema(\"graph_schema.pbtxt\")\n",
    "# graph_spec = tfgnn.create_graph_spec_from_schema_pb(graph_schema)\n",
    "# train_dataset_provider = runner.TFRecordDatasetProvider(file_pattern=\"train.tfrecord\")\n",
    "# train_dataset = train_dataset_provider.get_dataset(context=tf.distribute.InputContext())\n",
    "# train_dataset = train_dataset.map(lambda serialized: tfgnn.parse_single_example(serialized=serialized, spec=graph_spec))\n",
    "# graph_tensor = train_dataset.get_single_element()\n",
    "type(graph_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9053666-1f72-4165-aef9-c99e35da4817",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1764628322.682854   11501 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20070 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:2d:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# graph_schema = tfgnn.read_schema(\"graph_schema.pbtxt\")\n",
    "\n",
    "graph, label = dataset[0]\n",
    "SIZE=2449029\n",
    "\n",
    "graph_tensor = tfgnn.GraphTensor.from_pieces(\n",
    "    node_sets={\n",
    "       \"product\": tfgnn.NodeSet.from_fields(\n",
    "           sizes = tf.constant([2449029]),\n",
    "           features={\n",
    "               \"id\": tf.range(0,SIZE),\n",
    "               \"feature\": tf.constant(graph[\"node_feat\"]),\n",
    "               \"label\": tf.constant(label)\n",
    "           }\n",
    "       )\n",
    "   },\n",
    "    edge_sets = {\n",
    "      \"bought_together\": tfgnn.EdgeSet.from_fields(\n",
    "          sizes = tf.constant([graph[\"edge_index\"].shape[1]]),\n",
    "          adjacency = tfgnn.Adjacency.from_indices(\n",
    "              source = (\"product\", tf.constant(graph[\"edge_index\"][0,:])),\n",
    "              target = (\"product\", tf.constant(graph[\"edge_index\"][1,:])),\n",
    "          )\n",
    "      )  \n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a1a0aa8-5053-45c0-a047-5c587239d423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_tensor = tfgnn.GraphTensor.from_pieces(\n",
    "#     node_sets={\n",
    "#        \"product\": tfgnn.NodeSet.from_fields(\n",
    "#            sizes = tf.constant([train_idx.shape[0]]),\n",
    "#            features={\n",
    "#                \"id\": tf.constant(train_idx),\n",
    "#                \"feature\": tf.constant(train_node_feat),\n",
    "#                \"label\": tf.constant(train_label)\n",
    "#            }\n",
    "#        )\n",
    "#    },\n",
    "#     edge_sets = {\n",
    "#       \"bought_together\": tfgnn.EdgeSet.from_fields(\n",
    "#           sizes = tf.constant([train_edge_index.shape[1]]),\n",
    "#           adjacency = tfgnn.Adjacency.from_indices(\n",
    "#               source = (\"product\", tf.constant(train_edge_index[0,:])),\n",
    "#               target = (\"product\", tf.constant(train_edge_index[1,:])),\n",
    "#           )\n",
    "#       )  \n",
    "#     },\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e9bed97-cc2e-4b54-acdc-0299a6e2ad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_graph_tensor = tfgnn.GraphTensor.from_pieces(\n",
    "#     node_sets={\n",
    "#        \"product\": tfgnn.NodeSet.from_fields(\n",
    "#            sizes = tf.constant([valid_idx.shape[0]]),\n",
    "#            features={\n",
    "#                \"id\": tf.constant(valid_idx),\n",
    "#                \"feature\": tf.constant(valid_node_feat),\n",
    "#                \"label\": tf.constant(valid_label)\n",
    "#            }\n",
    "#        )\n",
    "#    },\n",
    "#     edge_sets = {\n",
    "#       \"bought_together\": tfgnn.EdgeSet.from_fields(\n",
    "#           sizes = tf.constant([valid_edge_index.shape[1]]),\n",
    "#           adjacency = tfgnn.Adjacency.from_indices(\n",
    "#               source = (\"product\", tf.constant(valid_edge_index[0,:])),\n",
    "#               target = (\"product\", tf.constant(valid_edge_index[1,:])),\n",
    "#           )\n",
    "#       )  \n",
    "#     },\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38b401aa-63c5-4d54-9102-4e8c38edbcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampling_sizes = {\n",
    "    \"bought_together\": 8,\n",
    "}\n",
    "\n",
    "# def create_sampling_model(full_graph_tensor: tfgnn.GraphTensor, sizes: Mapping[str, int]) -> tf.keras.Model:\n",
    "\n",
    "#     def edge_sampler(sampling_op: tfgnn.sampler.SamplingOp):    \n",
    "#         edge_set_name = sampling_op.edge_set_name\n",
    "#         sample_size = sizes[edge_set_name]\n",
    "#         return sampler.InMemUniformEdgesSampler.from_graph_tensor(\n",
    "#             full_graph_tensor,\n",
    "#             edge_set_name, sample_size=sample_size\n",
    "#         )\n",
    "#     def get_features(node_set_name: tfgnn.NodeSetName):\n",
    "#         return sampler.InMemIndexToFeaturesAccessor.from_graph_tensor(\n",
    "#             full_graph_tensor,\n",
    "#             node_set_name\n",
    "#         )\n",
    "\n",
    "#     sampling_spec_builder = tfgnn.sampler.SamplingSpecBuilder(graph_schema)\n",
    "#     seed = sampling_spec_builder.seed(\"product\")\n",
    "#     products_bought_together = seed.sample(sizes[\"bought_together\"], \"bought_together\", op_name=\"bt\")\n",
    "#     sampling_spec = sampling_spec_builder.build()\n",
    "#     model = sampler.create_sampling_model_from_spec(graph_schema, sampling_spec, edge_sampler, get_features, seed_node_dtype=tf.int64)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2befa5b-ddb2-4906-a046-1af4a24abe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SubgraphDatasetProvider(runner.DatasetProvider):\n",
    "#     \"Dataset provider\"\n",
    "\n",
    "#     def __init__(self,\n",
    "#                 full_graph_tensor: tfgnn.GraphTensor,\n",
    "#                 sizes: Mapping[str, int],\n",
    "#                 dataset: tf.data.Dataset,\n",
    "#                 split_name: str):\n",
    "#         self._sampling_model = create_sampling_model(full_graph_tensor, sizes)\n",
    "#         self.input_graph_spec = self._sampling_model.output.spec\n",
    "#         self._seed_dataset = dataset\n",
    "#         self._split_name = split_name\n",
    "#     def get_dataset(self, context: tf.distribute.InputContext) -> tf.data.Dataset:\n",
    "#         \"\"\"Creates TF dataset\"\"\"\n",
    "#         ds = self._seed_dataset.shard(num_shards=context.num_input_pipelines, index = context.input_pipeline_id)\n",
    "#         # TODO Update to use correct number of training examples per type\n",
    "#         if self._split_name == \"train\":\n",
    "#             ds = ds.shuffle(train_idx.shape[0]).repeat()\n",
    "#         ds = ds.batch(128)\n",
    "#         ds = ds.map(\n",
    "#             functools.partial(self.sample),\n",
    "#             num_parallel_calls=tf.data.AUTOTUNE,\n",
    "#             deterministic=False,\n",
    "#         )\n",
    "#         return ds.unbatch().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "#     def sample(self, seeds: tf.Tensor) -> tfgnn.GraphTensor:\n",
    "#         # seeds = tf.cast(seeds, tf.int32)\n",
    "#         batch_size = tf.size(seeds)\n",
    "#         # print(f\"batch_size={batch_size}\")\n",
    "#         seeds_ragged = tf.RaggedTensor.from_row_lengths(seeds, tf.ones([batch_size], dtype=tf.int64))\n",
    "#         print(seeds_ragged)\n",
    "#         return self._sampling_model(seeds_ragged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30b535af-439a-4a3e-ab4b-d961598f8b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mapping types may not work well with tf.nest. Prefer using MutableMapping for <class 'tensorflow_gnn.graph.graph_tensor._ImmutableMapping'>\n",
      "WARNING:tensorflow:Mapping types may not work well with tf.nest. Prefer using MutableMapping for <class 'tensorflow_gnn.graph.graph_tensor._ImmutableMapping'>\n"
     ]
    }
   ],
   "source": [
    "train_ds_provider = SubgraphDatasetProvider(graph_tensor, train_sampling_sizes, tf.data.Dataset.from_tensor_slices(train_idx), \"train\", train_idx.shape[0])\n",
    "valid_ds_provider = SubgraphDatasetProvider(graph_tensor, train_sampling_sizes, tf.data.Dataset.from_tensor_slices(valid_idx), \"valid\", train_idx.shape[0])\n",
    "test_ds_provider = SubgraphDatasetProvider(graph_tensor, train_sampling_sizes, tf.data.Dataset.from_tensor_slices(test_idx), \"test\", train_idx.shape[0])\n",
    "\n",
    "example_input_graph_spec = train_ds_provider.input_graph_spec._unbatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1db5e7ea-3f99-4dc6-bf6d-884b38be4b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MirroredStrategy for GPUs\n",
      "GPU 0: NVIDIA GeForce RTX 3090 (UUID: GPU-b2dd31a4-1d4c-6d81-647d-e36ea0e64af9)\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Found 1 replicas in sync\n"
     ]
    }
   ],
   "source": [
    "if tf.config.list_physical_devices(\"TPU\"):\n",
    "  print(f\"Using TPUStrategy\")\n",
    "  min_nodes_per_component = {\"paper\": 1}\n",
    "  strategy = runner.TPUStrategy(\"local\")\n",
    "  train_padding = runner.FitOrSkipPadding(example_input_graph_spec, train_ds_provider, min_nodes_per_component)\n",
    "  valid_padding = runner.TightPadding(example_input_graph_spec, valid_ds_provider, min_nodes_per_component)\n",
    "elif tf.config.list_physical_devices(\"GPU\"):\n",
    "  print(f\"Using MirroredStrategy for GPUs\")\n",
    "  gpu_list = !nvidia-smi -L\n",
    "  print(\"\\n\".join(gpu_list))\n",
    "  strategy = tf.distribute.MirroredStrategy()\n",
    "  train_padding = None\n",
    "  valid_padding = None\n",
    "else:\n",
    "  print(f\"Using default strategy\")\n",
    "  strategy = tf.distribute.get_strategy()\n",
    "  train_padding = None\n",
    "  valid_padding = None\n",
    "print(f\"Found {strategy.num_replicas_in_sync} replicas in sync\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ce078a4-881d-4e45-b397-5ac24ab80865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_node_features(node_set: tfgnn.NodeSet, node_set_name: str):\n",
    "    if node_set_name == \"product\":\n",
    "        return {\"feature\": node_set[\"feature\"], \"label\": node_set[\"label\"]}\n",
    "    raise KeyError(f\"Unexpected node_set_name='{node_set_name}'\")\n",
    "\n",
    "def drop_all_features(_, **unused_kwargs):\n",
    "    return {}\n",
    "\n",
    "process_features = tfgnn.keras.layers.MapFeatures(\n",
    "    context_fn=drop_all_features,\n",
    "    node_sets_fn=process_node_features,\n",
    "    edge_sets_fn=drop_all_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2747cc15-3c37-4cb3-87e0-4a7a0108b613",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_readout = tfgnn.keras.layers.AddReadoutFromFirstNode(\"seed\", node_set_name=\"product\")\n",
    "move_label_to_readout = tfgnn.keras.layers.StructuredReadoutIntoFeature(\n",
    "    \"seed\", feature_name=\"label\", new_feature_name=\"category\", remove_input_feature=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cec2b493-c949-44ec-b899-d103c06d5a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_processors = [\n",
    "    process_features,\n",
    "    add_readout,\n",
    "    move_label_to_readout,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ab67318-bb0b-4a7e-b4b8-f9a5fd83721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_state_dim = 128\n",
    "\n",
    "def set_initial_node_states(node_set: tfgnn.NodeSet, node_set_name: str):\n",
    "    if node_set_name == \"product\":\n",
    "        return tf.keras.layers.Dense(node_state_dim, \"relu\")(node_set[\"feature\"])\n",
    "    raise KeyError(f\"Unexpected node_set_name='{node_set_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15b8eb9e-b87d-4ea6-8438-9e70f95ae0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_graph_updates = 1\n",
    "message_dim = 128\n",
    "state_dropout_rate = 0.2\n",
    "l2_regularization= 1e-5\n",
    "\n",
    "def model_fn(graph_tensor_spec: tfgnn.GraphTensorSpec):\n",
    "    graph = inputs = tf.keras.layers.Input(type_spec=graph_tensor_spec)\n",
    "    graph = tfgnn.keras.layers.MapFeatures(\n",
    "        node_sets_fn = set_initial_node_states)(graph)\n",
    "    for i in range(num_graph_updates):\n",
    "        graph = mt_albis.MtAlbisGraphUpdate(\n",
    "            units = node_state_dim,\n",
    "            message_dim = message_dim,\n",
    "            receiver_tag = tfgnn.SOURCE,\n",
    "            node_set_names = None if i < num_graph_updates - 1 else [\"product\"],\n",
    "            simple_conv_reduce_type=\"mean|sum\",\n",
    "            state_dropout_rate=state_dropout_rate,\n",
    "            l2_regularization=l2_regularization,\n",
    "            normalization_type=\"layer\",\n",
    "            next_state_type=\"residual\",\n",
    "        )(graph)\n",
    "    return tf.keras.Model(inputs, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "376c89bd-9f35-4415-bfe1-ec70e5abd04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(label.flatten()).shape gives 47\n",
    "task = runner.NodeMulticlassClassification(\n",
    "    num_classes=47,\n",
    "    label_feature_name=\"category\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "405a5c0a-a498-488f-a28f-dfd784ba030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_batch_size = 128\n",
    "epochs = 30\n",
    "initial_learning_rate = 0.001\n",
    "\n",
    "if tf.config.list_physical_devices(\"TPU\"):\n",
    "    epoch_divisor = 1\n",
    "else:\n",
    "    epoch_divisor = 1\n",
    "\n",
    "steps_per_epoch = NUM_TRAINING_SAMPLES // global_batch_size // epoch_divisor\n",
    "validation_steps = NUM_VALIDATION_SAMPLES // global_batch_size // epoch_divisor\n",
    "\n",
    "learning_rate = tf.keras.optimizers.schedules.CosineDecay(initial_learning_rate, steps_per_epoch*epochs)\n",
    "optimizer_fn = functools.partial(tf.keras.optimizers.Adam, learning_rate=learning_rate)\n",
    "\n",
    "trainer = runner.KerasTrainer(\n",
    "    strategy=strategy,\n",
    "    model_dir=\"gnn_model\",\n",
    "    callbacks=[TensorBoard(log_dir=\"logs\")],\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    restore_best_weights=False,\n",
    "    checkpoint_every_n_steps=\"never\",\n",
    "    summarize_every_n_steps=\"never\",\n",
    "    backup_and_restore=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4dd6d340-f68a-4c1a-bf6f-43352af624e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.RaggedTensor(values=Tensor(\"args_0:0\", shape=(None,), dtype=int64), row_splits=Tensor(\"RaggedFromRowLengths/control_dependency:0\", shape=(None,), dtype=int64))\n",
      "tf.RaggedTensor(values=Tensor(\"args_0:0\", shape=(None,), dtype=int64), row_splits=Tensor(\"RaggedFromRowLengths/control_dependency:0\", shape=(None,), dtype=int64))\n",
      "Epoch 1/30\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 22:32:31.203334: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002\n",
      "2025-12-01 22:32:31.236970: I external/local_xla/xla/service/service.cc:163] XLA service 0x75a6307ac240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-12-01 22:32:31.236982: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2025-12-01 22:32:31.245207: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1764628351.314205   11587 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536/1536 [==============================] - 11s 6ms/step - loss: 0.7394 - sparse_categorical_accuracy: 0.7964 - sparse_categorical_crossentropy: 0.7352 - val_loss: 0.5285 - val_sparse_categorical_accuracy: 0.8554 - val_sparse_categorical_crossentropy: 0.5236\n",
      "Epoch 2/30\n",
      "1536/1536 [==============================] - 8s 5ms/step - loss: 0.5013 - sparse_categorical_accuracy: 0.8597 - sparse_categorical_crossentropy: 0.4957 - val_loss: 0.4950 - val_sparse_categorical_accuracy: 0.8643 - val_sparse_categorical_crossentropy: 0.4888\n",
      "Epoch 3/30\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.4523 - sparse_categorical_accuracy: 0.8737 - sparse_categorical_crossentropy: 0.4455 - val_loss: 0.4669 - val_sparse_categorical_accuracy: 0.8742 - val_sparse_categorical_crossentropy: 0.4595\n",
      "Epoch 4/30\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.4246 - sparse_categorical_accuracy: 0.8812 - sparse_categorical_crossentropy: 0.4166 - val_loss: 0.4522 - val_sparse_categorical_accuracy: 0.8761 - val_sparse_categorical_crossentropy: 0.4436\n",
      "Epoch 5/30\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.4061 - sparse_categorical_accuracy: 0.8867 - sparse_categorical_crossentropy: 0.3970 - val_loss: 0.4440 - val_sparse_categorical_accuracy: 0.8820 - val_sparse_categorical_crossentropy: 0.4344\n",
      "Epoch 6/30\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.3933 - sparse_categorical_accuracy: 0.8906 - sparse_categorical_crossentropy: 0.3832 - val_loss: 0.4301 - val_sparse_categorical_accuracy: 0.8824 - val_sparse_categorical_crossentropy: 0.4195\n",
      "Epoch 7/30\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.3809 - sparse_categorical_accuracy: 0.8938 - sparse_categorical_crossentropy: 0.3700 - val_loss: 0.4352 - val_sparse_categorical_accuracy: 0.8855 - val_sparse_categorical_crossentropy: 0.4238\n",
      "Epoch 8/30\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.3697 - sparse_categorical_accuracy: 0.8973 - sparse_categorical_crossentropy: 0.3580 - val_loss: 0.4339 - val_sparse_categorical_accuracy: 0.8864 - val_sparse_categorical_crossentropy: 0.4218\n",
      "Epoch 9/30\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.3641 - sparse_categorical_accuracy: 0.8985 - sparse_categorical_crossentropy: 0.3518 - val_loss: 0.4345 - val_sparse_categorical_accuracy: 0.8847 - val_sparse_categorical_crossentropy: 0.4218\n",
      "Epoch 10/30\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.3567 - sparse_categorical_accuracy: 0.9005 - sparse_categorical_crossentropy: 0.3438 - val_loss: 0.4330 - val_sparse_categorical_accuracy: 0.8871 - val_sparse_categorical_crossentropy: 0.4200\n",
      "Epoch 11/30\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.3486 - sparse_categorical_accuracy: 0.9035 - sparse_categorical_crossentropy: 0.3354 - val_loss: 0.4302 - val_sparse_categorical_accuracy: 0.8884 - val_sparse_categorical_crossentropy: 0.4168\n",
      "Epoch 12/30\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.3431 - sparse_categorical_accuracy: 0.9046 - sparse_categorical_crossentropy: 0.3295 - val_loss: 0.4298 - val_sparse_categorical_accuracy: 0.8879 - val_sparse_categorical_crossentropy: 0.4161\n",
      "Epoch 13/30\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.3354 - sparse_categorical_accuracy: 0.9066 - sparse_categorical_crossentropy: 0.3215 - val_loss: 0.4344 - val_sparse_categorical_accuracy: 0.8892 - val_sparse_categorical_crossentropy: 0.4205\n",
      "Epoch 14/30\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.3301 - sparse_categorical_accuracy: 0.9084 - sparse_categorical_crossentropy: 0.3161 - val_loss: 0.4304 - val_sparse_categorical_accuracy: 0.8908 - val_sparse_categorical_crossentropy: 0.4163\n",
      "Epoch 15/30\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.3231 - sparse_categorical_accuracy: 0.9101 - sparse_categorical_crossentropy: 0.3090 - val_loss: 0.4294 - val_sparse_categorical_accuracy: 0.8915 - val_sparse_categorical_crossentropy: 0.4152\n",
      "Epoch 16/30\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.3190 - sparse_categorical_accuracy: 0.9113 - sparse_categorical_crossentropy: 0.3048 - val_loss: 0.4222 - val_sparse_categorical_accuracy: 0.8908 - val_sparse_categorical_crossentropy: 0.4079\n",
      "Epoch 17/30\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.3124 - sparse_categorical_accuracy: 0.9137 - sparse_categorical_crossentropy: 0.2982 - val_loss: 0.4237 - val_sparse_categorical_accuracy: 0.8905 - val_sparse_categorical_crossentropy: 0.4094\n",
      "Epoch 18/30\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.3094 - sparse_categorical_accuracy: 0.9140 - sparse_categorical_crossentropy: 0.2951 - val_loss: 0.4292 - val_sparse_categorical_accuracy: 0.8908 - val_sparse_categorical_crossentropy: 0.4149\n",
      "Epoch 19/30\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.3053 - sparse_categorical_accuracy: 0.9148 - sparse_categorical_crossentropy: 0.2911 - val_loss: 0.4236 - val_sparse_categorical_accuracy: 0.8925 - val_sparse_categorical_crossentropy: 0.4093\n",
      "Epoch 20/30\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.2988 - sparse_categorical_accuracy: 0.9165 - sparse_categorical_crossentropy: 0.2845 - val_loss: 0.4307 - val_sparse_categorical_accuracy: 0.8903 - val_sparse_categorical_crossentropy: 0.4165\n",
      "Epoch 21/30\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.2916 - sparse_categorical_accuracy: 0.9188 - sparse_categorical_crossentropy: 0.2773 - val_loss: 0.4209 - val_sparse_categorical_accuracy: 0.8926 - val_sparse_categorical_crossentropy: 0.4067\n",
      "Epoch 22/30\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.2928 - sparse_categorical_accuracy: 0.9183 - sparse_categorical_crossentropy: 0.2786 - val_loss: 0.4245 - val_sparse_categorical_accuracy: 0.8932 - val_sparse_categorical_crossentropy: 0.4104\n",
      "Epoch 23/30\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.2888 - sparse_categorical_accuracy: 0.9195 - sparse_categorical_crossentropy: 0.2746 - val_loss: 0.4243 - val_sparse_categorical_accuracy: 0.8918 - val_sparse_categorical_crossentropy: 0.4102\n",
      "Epoch 24/30\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.2855 - sparse_categorical_accuracy: 0.9207 - sparse_categorical_crossentropy: 0.2714 - val_loss: 0.4222 - val_sparse_categorical_accuracy: 0.8935 - val_sparse_categorical_crossentropy: 0.4081\n",
      "Epoch 25/30\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.2820 - sparse_categorical_accuracy: 0.9213 - sparse_categorical_crossentropy: 0.2680 - val_loss: 0.4230 - val_sparse_categorical_accuracy: 0.8929 - val_sparse_categorical_crossentropy: 0.4090\n",
      "Epoch 26/30\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.2796 - sparse_categorical_accuracy: 0.9225 - sparse_categorical_crossentropy: 0.2655 - val_loss: 0.4210 - val_sparse_categorical_accuracy: 0.8933 - val_sparse_categorical_crossentropy: 0.4069\n",
      "Epoch 27/30\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.2787 - sparse_categorical_accuracy: 0.9218 - sparse_categorical_crossentropy: 0.2646 - val_loss: 0.4214 - val_sparse_categorical_accuracy: 0.8936 - val_sparse_categorical_crossentropy: 0.4074\n",
      "Epoch 28/30\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.2772 - sparse_categorical_accuracy: 0.9230 - sparse_categorical_crossentropy: 0.2632 - val_loss: 0.4222 - val_sparse_categorical_accuracy: 0.8948 - val_sparse_categorical_crossentropy: 0.4082\n",
      "Epoch 29/30\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.2772 - sparse_categorical_accuracy: 0.9224 - sparse_categorical_crossentropy: 0.2632 - val_loss: 0.4228 - val_sparse_categorical_accuracy: 0.8950 - val_sparse_categorical_crossentropy: 0.4088\n",
      "Epoch 30/30\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.2752 - sparse_categorical_accuracy: 0.9228 - sparse_categorical_crossentropy: 0.2612 - val_loss: 0.4252 - val_sparse_categorical_accuracy: 0.8928 - val_sparse_categorical_crossentropy: 0.4111\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: gnn_model/export/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gnn_model/export/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RunResult(preprocess_model=<tf_keras.src.engine.functional.Functional object at 0x75a68c28d7f0>, base_model=<tf_keras.src.engine.sequential.Sequential object at 0x75a621f85a30>, trained_model=<tf_keras.src.engine.functional.Functional object at 0x75a68c4dcf80>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_exporter = runner.KerasModelExporter(output_names=\"product_category\")\n",
    "runner.run(\n",
    "    gtspec=example_input_graph_spec,\n",
    "    train_ds_provider=train_ds_provider,\n",
    "    train_padding=train_padding,\n",
    "    # valid_ds_provider=None,\n",
    "    valid_ds_provider=valid_ds_provider,\n",
    "    valid_padding=valid_padding,\n",
    "    global_batch_size=global_batch_size,\n",
    "    epochs=epochs,\n",
    "    feature_processors=feature_processors,\n",
    "    model_fn=model_fn,\n",
    "    task=task,\n",
    "    optimizer_fn=optimizer_fn,\n",
    "    trainer=trainer,\n",
    "    model_exporters=[model_exporter],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d4e0c0e-682e-40ce-87da-7ac3bcae6fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.RaggedTensor(values=Tensor(\"args_0:0\", shape=(None,), dtype=int64), row_splits=Tensor(\"RaggedFromRowLengths/control_dependency:0\", shape=(None,), dtype=int64))\n",
      "The predicted class for input 0 is   7 with predicted probability 0.9996, real values is 7\n",
      "The predicted class for input 1 is   7 with predicted probability 0.9883, real values is 7\n",
      "The predicted class for input 2 is   6 with predicted probability 0.9388, real values is 3\n",
      "The predicted class for input 3 is   4 with predicted probability 0.9995, real values is 4\n",
      "The predicted class for input 4 is   7 with predicted probability 0.9999, real values is 7\n",
      "The predicted class for input 5 is   3 with predicted probability 0.8799, real values is 12\n",
      "The predicted class for input 6 is   3 with predicted probability 0.7968, real values is 11\n",
      "The predicted class for input 7 is   4 with predicted probability 1.0, real values is 4\n",
      "The predicted class for input 8 is  13 with predicted probability 0.974, real values is 15\n",
      "The predicted class for input 9 is   3 with predicted probability 0.9705, real values is 3\n"
     ]
    }
   ],
   "source": [
    "saved_model = tf.saved_model.load(os.path.join(\"gnn_model\", \"export\"))\n",
    "signature_fn = saved_model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "\n",
    "def _clean_example_for_serving(graph_tensor):\n",
    "    label = graph_tensor.node_sets[\"product\"][\"label\"][0][0].numpy()\n",
    "    graph_tensor = graph_tensor.remove_features(node_sets={\"product\": [\"label\"]})\n",
    "    serialized_example = tfgnn.write_example(graph_tensor)\n",
    "    return label, serialized_example.SerializeToString()\n",
    "\n",
    "num_examples = 10\n",
    "demo_ds = valid_ds_provider.get_dataset(tf.distribute.InputContext())\n",
    "dds = itertools.islice(demo_ds, num_examples)\n",
    "labels, serialized_examples = zip(*[_clean_example_for_serving(gt) for gt in dds])\n",
    "labels = list(labels)\n",
    "serialized_examples = list(serialized_examples)\n",
    "ds = tf.data.Dataset.from_tensor_slices(serialized_examples)\n",
    "input_dict = {\"examples\": next(iter(ds.batch(num_examples)))}\n",
    "output_dict = signature_fn(**input_dict)\n",
    "logits = output_dict[\"product_category\"]\n",
    "probabilities = tf.math.softmax(logits).numpy()\n",
    "classes = probabilities.argmax(axis = 1)\n",
    "for i, c in enumerate(classes):\n",
    "    print(f\"The predicted class for input {i} is {c:3} \"\n",
    "          f\"with predicted probability {probabilities[i, c]:.4}, real values is {labels[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4659baa-6b66-4b7d-8ee2-fc362d280daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
