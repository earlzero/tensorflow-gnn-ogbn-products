{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c205d800-aa97-4ec8-adbc-1a0b1aeffe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "from ogb.nodeproppred import NodePropPredDataset\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_gnn as tfgnn\n",
    "from tensorflow_gnn import runner\n",
    "from typing import Mapping\n",
    "from tensorflow_gnn.experimental import sampler\n",
    "from tensorflow_gnn.models import mt_albis\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ed9e675-558f-44c7-be94-9ef6bcc16294",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NodePropPredDataset(name = \"ogbn-products\", root = 'dataset/')\n",
    "split_idx = dataset.get_idx_split()\n",
    "train_idx, valid_idx, test_idx = split_idx[\"train\"], split_idx[\"valid\"], split_idx[\"test\"]\n",
    "NUM_TRAINING_SAMPLES=train_idx.shape[0]\n",
    "NUM_VALIDATION_SAMPLES = valid_idx.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ff08c192-777b-4dda-8e70-6d016e575056",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph, label = dataset[0]\n",
    "mask0=np.isin(graph[\"edge_index\"][0],train_idx)\n",
    "mask1=np.isin(graph[\"edge_index\"][1],train_idx)\n",
    "\n",
    "mask = mask0 & mask1\n",
    "indices = np.where(mask)[0]\n",
    "train_edge_index=graph[\"edge_index\"][:, indices]\n",
    "train_node_feat = graph[\"node_feat\"][train_idx,:]\n",
    "train_label = label[train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4a9d78-523c-4870-ab61-5db17576bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph, label = dataset[0]\n",
    "mask0=np.isin(graph[\"edge_index\"][0],train_idx)\n",
    "mask1=np.isin(graph[\"edge_index\"][1],train_idx)\n",
    "\n",
    "mask = mask0 & mask1\n",
    "indices = np.where(mask)[0]\n",
    "train_edge_index=graph[\"edge_index\"][:, indices]\n",
    "train_node_feat = graph[\"node_feat\"][train_idx,:]\n",
    "train_label = label[train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b192796-4c46-42d6-802b-637f7512aec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_schema = tfgnn.read_schema(\"graph_schema.pbtxt\")\n",
    "# graph_spec = tfgnn.create_graph_spec_from_schema_pb(graph_schema)\n",
    "# train_dataset_provider = runner.TFRecordDatasetProvider(file_pattern=\"train.tfrecord\")\n",
    "# train_dataset = train_dataset_provider.get_dataset(context=tf.distribute.InputContext())\n",
    "# train_dataset = train_dataset.map(lambda serialized: tfgnn.parse_single_example(serialized=serialized, spec=graph_spec))\n",
    "# graph_tensor = train_dataset.get_single_element()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c9053666-1f72-4165-aef9-c99e35da4817",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_schema = tfgnn.read_schema(\"graph_schema.pbtxt\")\n",
    "\n",
    "graph_tensor = tfgnn.GraphTensor.from_pieces(\n",
    "    node_sets={\n",
    "       \"product\": tfgnn.NodeSet.from_fields(\n",
    "           sizes = tf.constant([train_idx.shape[0]]),\n",
    "           features={\n",
    "               \"id\": tf.constant(train_idx),\n",
    "               \"feature\": tf.constant(train_node_feat),\n",
    "               \"label\": tf.constant(train_label)\n",
    "           }\n",
    "       )\n",
    "   },\n",
    "    edge_sets = {\n",
    "      \"bought_together\": tfgnn.EdgeSet.from_fields(\n",
    "          sizes = tf.constant([train_edge_index.shape[1]]),\n",
    "          adjacency = tfgnn.Adjacency.from_indices(\n",
    "              source = (\"product\", tf.constant(train_edge_index[0,:])),\n",
    "              target = (\"product\", tf.constant(train_edge_index[1,:])),\n",
    "          )\n",
    "      )  \n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "38b401aa-63c5-4d54-9102-4e8c38edbcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampling_sizes = {\n",
    "    \"bought_together\": 8,\n",
    "}\n",
    "\n",
    "def create_sampling_model(full_graph_tensor: tfgnn.GraphTensor, sizes: Mapping[str, int]) -> tf.keras.Model:\n",
    "\n",
    "    def edge_sampler(sampling_op: tfgnn.sampler.SamplingOp):    \n",
    "        edge_set_name = sampling_op.edge_set_name\n",
    "        sample_size = sizes[edge_set_name]\n",
    "        return sampler.InMemUniformEdgesSampler.from_graph_tensor(\n",
    "            full_graph_tensor,\n",
    "            edge_set_name, sample_size=sample_size\n",
    "        )\n",
    "    def get_features(node_set_name: tfgnn.NodeSetName):\n",
    "        return sampler.InMemIndexToFeaturesAccessor.from_graph_tensor(\n",
    "            full_graph_tensor,\n",
    "            node_set_name\n",
    "        )\n",
    "\n",
    "    sampling_spec_builder = tfgnn.sampler.SamplingSpecBuilder(graph_schema)\n",
    "    seed = sampling_spec_builder.seed(\"product\")\n",
    "    products_bought_together = seed.sample(sizes[\"bought_together\"], \"bought_together\", op_name=\"bt\")\n",
    "    sampling_spec = sampling_spec_builder.build()\n",
    "    model = sampler.create_sampling_model_from_spec(graph_schema, sampling_spec, edge_sampler, get_features, seed_node_dtype=tf.int64)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2e329986-c235-4e22-b630-5e2299aaf963",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def node_sets_fn(node_set, *, node_set_name):\n",
    "#     features = node_set.get_features_dict()\n",
    "#     ids = features.pop('id')\n",
    "#     num_bins = 50000\n",
    "#     features['hashed_id'] = tf.cast(tf.keras.layers.Hashing(num_bins=num_bins)(ids), tf.int32)\n",
    "#     return features\n",
    "# graph = tfgnn.keras.layers.MapFeatures(node_sets_fn=node_sets_fn)(graph_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e2befa5b-ddb2-4906-a046-1af4a24abe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubgraphDatasetProvider(runner.DatasetProvider):\n",
    "    \"Dataset provider\"\n",
    "\n",
    "    def __init__(self,\n",
    "                full_graph_tensor: tfgnn.GraphTensor,\n",
    "                sizes: Mapping[str, int],\n",
    "                dataset: tf.data.Dataset):\n",
    "        self._sampling_model = create_sampling_model(full_graph_tensor, sizes)\n",
    "        self.input_graph_spec = self._sampling_model.output.spec\n",
    "        self._seed_dataset = dataset\n",
    "        \n",
    "    def get_dataset(self, context: tf.distribute.InputContext) -> tf.data.Dataset:\n",
    "        \"\"\"Creates TF dataset\"\"\"\n",
    "        ds = self._seed_dataset.shard(num_shards=context.num_input_pipelines, index = context.input_pipeline_id)\n",
    "        ds = ds.shuffle(NUM_TRAINING_SAMPLES).repeat()\n",
    "        ds = ds.batch(128)\n",
    "        ds = ds.map(\n",
    "            functools.partial(self.sample),\n",
    "            num_parallel_calls=tf.data.AUTOTUNE,\n",
    "            deterministic=False,\n",
    "        )\n",
    "        return ds.unbatch().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    def sample(self, seeds: tf.Tensor) -> tfgnn.GraphTensor:\n",
    "        # seeds = tf.cast(seeds, tf.int32)\n",
    "        batch_size = tf.size(seeds)\n",
    "        # print(f\"batch_size={batch_size}\")\n",
    "        seeds_ragged = tf.RaggedTensor.from_row_lengths(seeds, tf.ones([batch_size], dtype=tf.int64))\n",
    "        return self._sampling_model(seeds_ragged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "30b535af-439a-4a3e-ab4b-d961598f8b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_provider = SubgraphDatasetProvider(graph_tensor, train_sampling_sizes, tf.data.Dataset.from_tensor_slices(train_idx))\n",
    "valid_ds_provider = SubgraphDatasetProvider(graph_tensor, train_sampling_sizes, tf.data.Dataset.from_tensor_slices(valid_idx))\n",
    "\n",
    "example_input_graph_spec = train_ds_provider.input_graph_spec._unbatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1db5e7ea-3f99-4dc6-bf6d-884b38be4b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MirroredStrategy for GPUs\n",
      "GPU 0: NVIDIA GeForce RTX 3090 (UUID: GPU-b2dd31a4-1d4c-6d81-647d-e36ea0e64af9)\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Found 1 replicas in sync\n"
     ]
    }
   ],
   "source": [
    "if tf.config.list_physical_devices(\"TPU\"):\n",
    "  print(f\"Using TPUStrategy\")\n",
    "  min_nodes_per_component = {\"paper\": 1}\n",
    "  strategy = runner.TPUStrategy(\"local\")\n",
    "  train_padding = runner.FitOrSkipPadding(example_input_graph_spec, train_ds_provider, min_nodes_per_component)\n",
    "  valid_padding = runner.TightPadding(example_input_graph_spec, valid_ds_provider, min_nodes_per_component)\n",
    "elif tf.config.list_physical_devices(\"GPU\"):\n",
    "  print(f\"Using MirroredStrategy for GPUs\")\n",
    "  gpu_list = !nvidia-smi -L\n",
    "  print(\"\\n\".join(gpu_list))\n",
    "  strategy = tf.distribute.MirroredStrategy()\n",
    "  train_padding = None\n",
    "  valid_padding = None\n",
    "else:\n",
    "  print(f\"Using default strategy\")\n",
    "  strategy = tf.distribute.get_strategy()\n",
    "  train_padding = None\n",
    "  valid_padding = None\n",
    "print(f\"Found {strategy.num_replicas_in_sync} replicas in sync\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ce078a4-881d-4e45-b397-5ac24ab80865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_node_features(node_set: tfgnn.NodeSet, node_set_name: str):\n",
    "    if node_set_name == \"product\":\n",
    "        return {\"feature\": node_set[\"feature\"], \"label\": node_set[\"label\"]}\n",
    "    raise KeyError(f\"Unexpected node_set_name='{node_set_name}'\")\n",
    "\n",
    "def drop_all_features(_, **unused_kwargs):\n",
    "    return {}\n",
    "\n",
    "process_features = tfgnn.keras.layers.MapFeatures(\n",
    "    context_fn=drop_all_features,\n",
    "    node_sets_fn=process_node_features,\n",
    "    edge_sets_fn=drop_all_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2747cc15-3c37-4cb3-87e0-4a7a0108b613",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_readout = tfgnn.keras.layers.AddReadoutFromFirstNode(\"seed\", node_set_name=\"product\")\n",
    "move_label_to_readout = tfgnn.keras.layers.StructuredReadoutIntoFeature(\n",
    "    \"seed\", feature_name=\"label\", new_feature_name=\"category\", remove_input_feature=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cec2b493-c949-44ec-b899-d103c06d5a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_processors = [\n",
    "    process_features,\n",
    "    add_readout,\n",
    "    move_label_to_readout,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1ab67318-bb0b-4a7e-b4b8-f9a5fd83721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_state_dim = 128\n",
    "\n",
    "def set_initial_node_states(node_set: tfgnn.NodeSet, node_set_name: str):\n",
    "    if node_set_name == \"product\":\n",
    "        return tf.keras.layers.Dense(node_state_dim, \"relu\")(node_set[\"feature\"])\n",
    "    raise KeyError(f\"Unexpected node_set_name='{node_set_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "15b8eb9e-b87d-4ea6-8438-9e70f95ae0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_graph_updates = 1\n",
    "message_dim = 128\n",
    "state_dropout_rate = 0.2\n",
    "l2_regularization= 1e-5\n",
    "\n",
    "def model_fn(graph_tensor_spec: tfgnn.GraphTensorSpec):\n",
    "    graph = inputs = tf.keras.layers.Input(type_spec=graph_tensor_spec)\n",
    "    graph = tfgnn.keras.layers.MapFeatures(\n",
    "        node_sets_fn = set_initial_node_states)(graph)\n",
    "    for i in range(num_graph_updates):\n",
    "        graph = mt_albis.MtAlbisGraphUpdate(\n",
    "            units = node_state_dim,\n",
    "            message_dim = message_dim,\n",
    "            receiver_tag = tfgnn.SOURCE,\n",
    "            node_set_names = None if i < num_graph_updates - 1 else [\"product\"],\n",
    "            simple_conv_reduce_type=\"mean|sum\",\n",
    "            state_dropout_rate=state_dropout_rate,\n",
    "            l2_regularization=l2_regularization,\n",
    "            normalization_type=\"layer\",\n",
    "            next_state_type=\"residual\",\n",
    "        )(graph)\n",
    "    return tf.keras.Model(inputs, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "376c89bd-9f35-4415-bfe1-ec70e5abd04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(label.flatten()).shape gives 47\n",
    "task = runner.NodeMulticlassClassification(\n",
    "    num_classes=47,\n",
    "    label_feature_name=\"category\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "405a5c0a-a498-488f-a28f-dfd784ba030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_batch_size = 128\n",
    "epochs = 10\n",
    "initial_learning_rate = 0.001\n",
    "\n",
    "if tf.config.list_physical_devices(\"TPU\"):\n",
    "    epoch_divisor = 1\n",
    "else:\n",
    "    epoch_divisor = 1\n",
    "\n",
    "steps_per_epoch = NUM_TRAINING_SAMPLES // global_batch_size // epoch_divisor\n",
    "validation_steps = NUM_VALIDATION_SAMPLES // global_batch_size // epoch_divisor\n",
    "\n",
    "learning_rate = tf.keras.optimizers.schedules.CosineDecay(initial_learning_rate, steps_per_epoch*epochs)\n",
    "optimizer_fn = functools.partial(tf.keras.optimizers.Adam, learning_rate=learning_rate)\n",
    "\n",
    "trainer = runner.KerasTrainer(\n",
    "    strategy=strategy,\n",
    "    model_dir=\"/tmp/gnn_model\",\n",
    "    callbacks=[TensorBoard(log_dir=\"logs\")],\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    # validation_steps=validation_steps,\n",
    "    restore_best_weights=False,\n",
    "    checkpoint_every_n_steps=\"never\",\n",
    "    summarize_every_n_steps=\"never\",\n",
    "    backup_and_restore=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4dd6d340-f68a-4c1a-bf6f-43352af624e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size=Tensor(\"Size:0\", shape=(), dtype=int32)\n",
      "Epoch 1/10\n",
      "1536/1536 [==============================] - 8s 4ms/step - loss: 0.7331 - sparse_categorical_accuracy: 0.8008 - sparse_categorical_crossentropy: 0.7288\n",
      "Epoch 2/10\n",
      "1536/1536 [==============================] - 6s 4ms/step - loss: 0.4906 - sparse_categorical_accuracy: 0.8654 - sparse_categorical_crossentropy: 0.4851\n",
      "Epoch 3/10\n",
      "1536/1536 [==============================] - 6s 4ms/step - loss: 0.4399 - sparse_categorical_accuracy: 0.8788 - sparse_categorical_crossentropy: 0.4333\n",
      "Epoch 4/10\n",
      "1536/1536 [==============================] - 6s 4ms/step - loss: 0.4067 - sparse_categorical_accuracy: 0.8881 - sparse_categorical_crossentropy: 0.3993\n",
      "Epoch 5/10\n",
      "1536/1536 [==============================] - 6s 4ms/step - loss: 0.3816 - sparse_categorical_accuracy: 0.8948 - sparse_categorical_crossentropy: 0.3736\n",
      "Epoch 6/10\n",
      "1536/1536 [==============================] - 6s 4ms/step - loss: 0.3602 - sparse_categorical_accuracy: 0.9005 - sparse_categorical_crossentropy: 0.3519\n",
      "Epoch 7/10\n",
      "1536/1536 [==============================] - 6s 4ms/step - loss: 0.3455 - sparse_categorical_accuracy: 0.9048 - sparse_categorical_crossentropy: 0.3370\n",
      "Epoch 8/10\n",
      "1536/1536 [==============================] - 6s 4ms/step - loss: 0.3303 - sparse_categorical_accuracy: 0.9090 - sparse_categorical_crossentropy: 0.3217\n",
      "Epoch 9/10\n",
      "1536/1536 [==============================] - 6s 4ms/step - loss: 0.3240 - sparse_categorical_accuracy: 0.9104 - sparse_categorical_crossentropy: 0.3154\n",
      "Epoch 10/10\n",
      "1536/1536 [==============================] - 6s 4ms/step - loss: 0.3182 - sparse_categorical_accuracy: 0.9120 - sparse_categorical_crossentropy: 0.3096\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/gnn_model/export/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/gnn_model/export/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RunResult(preprocess_model=<tf_keras.src.engine.functional.Functional object at 0x7b0ddffeffb0>, base_model=<tf_keras.src.engine.sequential.Sequential object at 0x7b0f19383e30>, trained_model=<tf_keras.src.engine.functional.Functional object at 0x7b0f2940d370>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_exporter = runner.KerasModelExporter(output_names=\"product_category\")\n",
    "runner.run(\n",
    "    gtspec=example_input_graph_spec,\n",
    "    train_ds_provider=train_ds_provider,\n",
    "    train_padding=train_padding,\n",
    "    valid_ds_provider=None,\n",
    "    # valid_ds_provider=valid_ds_provider,\n",
    "    valid_padding=valid_padding,\n",
    "    global_batch_size=global_batch_size,\n",
    "    epochs=epochs,\n",
    "    feature_processors=feature_processors,\n",
    "    model_fn=model_fn,\n",
    "    task=task,\n",
    "    optimizer_fn=optimizer_fn,\n",
    "    trainer=trainer,\n",
    "    model_exporters=[model_exporter],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "997ed205-e463-4a2e-8d77-f215dc541731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphTensorSpec({'context': ContextSpec({'features': {}, 'sizes': TensorSpec(shape=(1,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, tf.int64, None), 'node_sets': {'product': NodeSetSpec({'features': {'id': TensorSpec(shape=(None,), dtype=tf.int32, name=None), 'feature': TensorSpec(shape=(None, 100), dtype=tf.int32, name=None), 'label': TensorSpec(shape=(None, 1), dtype=tf.int32, name=None)}, 'sizes': TensorSpec(shape=(1,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, tf.int64, None)}, 'edge_sets': {'bought_together': EdgeSetSpec({'features': {}, 'adjacency': AdjacencySpec({'#index.0': TensorSpec(shape=(None,), dtype=tf.int32, name=None), '#index.1': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, tf.int64, {'#index.0': 'product', '#index.1': 'product'}), 'sizes': TensorSpec(shape=(1,), dtype=tf.int32, name=None)}, TensorShape([]), tf.int32, tf.int64, None)}}, TensorShape([]), tf.int32, tf.int64, None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_graph_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c4859a8-20cb-4811-8173-666e2b1adb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mapping types may not work well with tf.nest. Prefer using MutableMapping for <class 'tensorflow_gnn.graph.graph_tensor._ImmutableMapping'>\n",
      "WARNING:tensorflow:Mapping types may not work well with tf.nest. Prefer using MutableMapping for <class 'tensorflow_gnn.graph.graph_tensor._ImmutableMapping'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<KerasTensor: type_spec=GraphTensorSpec({'context': ContextSpec({'features': {}, 'sizes': TensorSpec(shape=(None, 1), dtype=tf.int32, name=None)}, TensorShape([None]), tf.int32, tf.int64, None), 'node_sets': {'product': NodeSetSpec({'features': {'id': RaggedTensorSpec(TensorShape([None, None]), tf.int64, 1, tf.int64), 'feature': RaggedTensorSpec(TensorShape([None, None, 100]), tf.float32, 1, tf.int64), 'label': RaggedTensorSpec(TensorShape([None, None, 1]), tf.int64, 1, tf.int64)}, 'sizes': TensorSpec(shape=(None, 1), dtype=tf.int32, name=None)}, TensorShape([None]), tf.int32, tf.int64, None)}, 'edge_sets': {'bought_together': EdgeSetSpec({'features': {}, 'adjacency': AdjacencySpec({'#index.0': RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int64), '#index.1': RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int64)}, TensorShape([None]), tf.int32, tf.int64, {'#index.0': 'product', '#index.1': 'product'}), 'sizes': TensorSpec(shape=(None, 1), dtype=tf.int32, name=None)}, TensorShape([None]), tf.int32, tf.int64, None)}}, TensorShape([None]), tf.int32, tf.int64, None) (created by layer 'input.replace_features')>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_sampling_model(graph_tensor, train_sampling_sizes)\n",
    "model.output\n",
    "# graph.edge_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d4e0c0e-682e-40ce-87da-7ac3bcae6fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bought_together': EdgeSet(features={}, sizes=[10903266], adjacency=Adjacency(source=('product', <tf.Tensor: shape=(10903266,), dtype=tf.int64>), target=('product', <tf.Tensor: shape=(10903266,), dtype=tf.int64>)))}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_tensor.edge_sets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
